def get_rna_bigwigs(wildcards):
    """
    return all bigwigs generated by this workflow
    """
    def get_bigwig_strand(sample):
        if 'strandedness' in samples and config.get('bam_bigwig', False) and config.get('bam_bigwig').get('filter_by_strand', False):
            strandedness = samples["strandedness"].loc[sample]
            if strandedness in ['forward', 'yes', 'reverse']:
                return ['.fwd', '.rev']
        return ['']

    bigwigs = []
    for sample in samples.index:
        for bw in get_bigwig_strand(sample):
            bw = expand(f"{{result_dir}}/bigwigs/{samples.loc[sample]['assembly']}-{sample}.{config['bam_sorter']}-{config['bam_sort_order']}{bw}.bw", **config)
            bigwigs.extend(bw)
    return bigwigs


def get_strandedness(wildcards):
    sample = f"{wildcards.sample}"
    strandedness = samples["strandedness"].loc[sample]
    return strandedness

rule bam_stranded_bigwig:
    """
    Convert a bam file into two bigwig files, one for each strand    
    """
    input:
        bam=expand("{dedup_dir}/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.bam", **config),
        bai=expand("{dedup_dir}/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.bai", **config)
    output:
        forward=expand("{result_dir}/bigwigs/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.fwd.bw", **config),
        reverse=expand("{result_dir}/bigwigs/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.rev.bw", **config),
    params:
        flags=config['bam_bigwig']['deeptools'],
        strandedness=get_strandedness
    wildcard_constraints:
        sorting=config['bam_sort_order']
    log:
        expand("{log_dir}/bam_bigwig/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.log", **config),
    benchmark:
        expand("{benchmark_dir}/bam_bigwig/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.benchmark.txt", **config)[0]
    conda:
        "../envs/deeptools.yaml"
    threads: 20
    resources:
        deeptools_limit=1
    shell:
        """       
        direction1=forward
        direction2=reverse
        if [ {params.strandedness} == 'reverse' ]; then
            direction1=reverse
            direction2=forward
        fi
                    
        bamCoverage --bam {input.bam} --outFileName {output.forward} --filterRNAstrand $direction1 --numberOfProcessors {threads} {params.flags} --verbose >> {log} 2>&1 &&        
        bamCoverage --bam {input.bam} --outFileName {output.reverse} --filterRNAstrand $direction2 --numberOfProcessors {threads} {params.flags} --verbose >> {log} 2>&1
        """

rule bam_bigwig:
    """
    Convert a bam file into a bigwig file
    """
    input:
        bam=expand("{dedup_dir}/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.bam", **config),
        bai=expand("{dedup_dir}/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.bai", **config)
    output:
        expand("{result_dir}/bigwigs/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.bw", **config)
    params:
        config['bam_bigwig']['deeptools']
    wildcard_constraints:
        sorting=config['bam_sort_order']
    log:
        expand("{log_dir}/bam_bigwig/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.log", **config),
    benchmark:
        expand("{benchmark_dir}/bam_bigwig/{{assembly}}-{{sample}}.{{sorter}}-{{sorting}}.benchmark.txt", **config)[0]
    conda:
        "../envs/deeptools.yaml"
    threads: 20
    resources:
        deeptools_limit=1
    shell:
        """
        bamCoverage --bam {input.bam} --outFileName {output} --numberOfProcessors {threads} {params} --verbose >> {log} 2>&1
        """


rule twobit:
    """
    Generate a 2bit file for each assembly
    """
    input:
        expand("{genome_dir}/{{assembly}}/{{assembly}}.fa", **config)
    output:
        expand("{genome_dir}/{{assembly}}/{{assembly}}.2bit", **config)
    log:
        expand("{log_dir}/assembly_hub/{{assembly}}.2bit.log", **config)
    benchmark:
        expand("{benchmark_dir}/assembly_hub/{{assembly}}.2bit.benchmark.txt", **config)[0]
    conda:
        "../envs/assembly_hub.yaml"
    shell:
        "faToTwoBit {input[0]} {output[0]}"

# TODO: implement creation of these files and their integration in the assembly hub
# chrom.sizes = sizes.fa
# cytoBandIdeo.bb
# RMsoft.bed3
# gc5Base.bw
# Annot.bb


rule assembly_hub:
    """
    Create a trackhub with any number of genome assemblies (assembly hub).
     
    Must be hosted on your own machine in order to be viewed through the UCSC genome browser.
    """
    input:
        rna_bigwigs = get_rna_bigwigs,
        sizefiles   = expand(f"{{genome_dir}}/{{assemblies}}/{{assemblies}}.fa.sizes", **{**config, **{'assemblies': set(samples['assembly'])}}),
        twobitfiles = expand(f"{{genome_dir}}/{{assemblies}}/{{assemblies}}.2bit",     **{**config, **{'assemblies': set(samples['assembly'])}})
    output:
        directory(f"{config['result_dir']}/assembly_hub")
    params:
        sorter = config['bam_sorter'],
        sorting = config['bam_sort_order']
    log:
        f"{config['log_dir']}/assembly_hub/assembly_hub.log"
    benchmark:
        f"{config['benchmark_dir']}/assembly_hub/assembly_hub.benchmark.txt"
    run:
        import trackhub
        import os.path
        import re
        from contextlib import redirect_stdout

        def get_defaultPos(sizefile):
            # extract a default position spanning the first scaffold/chromosome in the sizefile.
            with open(sizefile, 'r') as file:
                dflt = file.readline().strip('\n').split('\t')
            return dflt[0] + ':0-' + str(min(int(dflt[1]), 100000))

        # output to log
        with open(str(log), 'w') as f:
            with redirect_stdout(f):

                # TODO: check if an existing hub exists, and extend it rather than overwrite if so.

                # start a shared hub
                hub = trackhub.Hub(
                    hub        =config.get('hubname',    'assembly'),
                    short_label=config.get('shortlabel', 'custom trackhub'), # 17 characters max
                    long_label =config.get('longlabel',  "Automated trackhub generated by the snakemake-workflows tool: \n"
                                                         "https://github.com/vanheeringen-lab/snakemake-workflows"),
                    email      =config.get('email',      'none@provided.com'))

                # link the genomes file to the hub
                genomes_file = trackhub.genomes_file.GenomesFile()
                hub.add_genomes_file(genomes_file)

                # add a genome and a tracks file to the genomes file for each assembly
                orderKey = 4800
                for assembly in set(samples['assembly']):

                    for file in input.twobitfiles:
                        if os.path.basename(file).startswith(assembly):
                            break
                    twobit_file = file
                    for file in input.sizefiles:
                        if os.path.basename(file).startswith(assembly):
                            break
                    defaultPos = get_defaultPos(file)

                    # add the assembly to the hub
                    genome = trackhub.Assembly(
                        genome=assembly,
                        twobit_file=twobit_file,
                        organism=assembly,       # required
                        defaultPos=defaultPos,
                        # scientificName="Biggus Footus",
                        # description="BigFoot V4",
                        # html_string="BIGFOOT V4 INFO\n",
                        orderKey=orderKey
                    )
                    genomes_file.add_genome(genome)
                    orderKey += 1

                    # create a trackDb
                    trackdb = trackhub.TrackDb()
                    genome.add_trackdb(trackdb)
                    priority = 1

                    for bw in input.rna_bigwigs:

                        sample_name = os.path.basename(bw).replace(assembly+'-', '').replace('.' + params.sorter + '-' + params.sorting, '').replace('.bw', '').replace(' ','')
                        #sample_name = re.sub('[^A-Za-z0-9]+', '', sample_name)
                        track = trackhub.Track(
                            name=sample_name,    # track names can't have any spaces or special chars.
                            source=bw,           # filename to build this track from
                            visibility='full',   # shows the full signal
                            color='0,0,0',       # black
                            autoScale='on',      # allow the track to autoscale
                            tracktype='bigWig',  # required when making a track
                            priority = priority
                        )
                        trackdb.add_tracks(track)
                        priority += 1

            # # TODO: upload rna bigwigs and atac bigfiles in one go
            #
            # for peak_caller in config['peak_caller']:
            #     conditions = set()
            #     for sample in samples[samples['assembly'] == assembly].index:
            #         if 'condition' in samples:
            #             if samples.loc[sample, 'condition'] not in conditions:
            #                 bigpeak = f"{config['result_dir']}/{peak_caller}/{samples.loc[sample, 'condition']}-{assembly}.bigNarrowPeak"
            #             else:
            #                 bigpeak = False
            #             conditions.add(samples.loc[sample, 'condition'])
            #             sample_name = f"{samples.loc[sample, 'condition']}{peak_caller}PEAK"
            #         else:
            #             bigpeak = f"{config['result_dir']}/{peak_caller}/{assembly}-{sample}.bigNarrowPeak"
            #             sample_name = f"{sample}{peak_caller}PEAK"
            #
            #         if bigpeak:
            #             track = trackhub.Track(
            #                 name=sample_name,           # track names can't have any spaces or special chars.
            #                 source=bigpeak,             # filename to build this track from
            #                 visibility='dense',         # shows the full signal
            #                 tracktype='bigNarrowPeak',  # required when making a track
            #                 priority=priority
            #             )
            #             priority += 1
            #             trackdb.add_tracks(track)
            #
            #         bigwig = f"{config['result_dir']}/{peak_caller}/{assembly}-{sample}.bw"
            #         sample_name = f"{sample}{peak_caller}BW"
            #
            #         track = trackhub.Track(
            #             name=sample_name,    # track names can't have any spaces or special chars.
            #             source=bigwig,       # filename to build this track from
            #             visibility='full',   # shows the full signal
            #             color='0,0,0',       # black
            #             autoScale='on',      # allow the track to autoscale
            #             tracktype='bigWig',  # required when making a track
            #             priority = priority
            #         )
            #
            #         # each track is added to the trackdb
            #         trackdb.add_tracks(track)
            #         priority += 1

        # create the hub folder with symlinks to all files
        trackhub.upload.stage_hub(hub, staging=output[0])

        # upload the hub
        if config.get('hub', False) and config.get('host', False):
            trackhub.upload.upload_hub(hub, host=config.get('host'), remote_dir=config.get('hub'))
            print('\nYour trackhub has been uploaded to:\n' + config.get('host') + ':' + config.get('hub') + '/' + config.get('hubname', 'trackhub') + 'hub.txt\n')
